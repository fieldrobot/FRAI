{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FRAI.ipynb","provenance":[],"collapsed_sections":["X_B5tSclUqCs","xc9yuzyxUf2n","K7TWF8F5U0ex","SELNfOVUUoyN","Li0J14aiU44E","ta5usZGXU28_","Ypl_TTkp0gqE"],"authorship_tag":"ABX9TyMapISlA90glHdwQZ5iStUT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# setup"],"metadata":{"id":"X_B5tSclUqCs"}},{"cell_type":"markdown","source":["connect google drive as sample storage"],"metadata":{"id":"ifqiVNKYQ6Qg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"JapnqeQx2qfd"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["load oridnary libraries"],"metadata":{"id":"fO1fCQTGSFQ0"}},{"cell_type":"code","source":["import os\n","\n","import cv2"],"metadata":{"id":"5qE5iBpBSH-u","executionInfo":{"status":"ok","timestamp":1652988611215,"user_tz":-120,"elapsed":393,"user":{"displayName":"Simon Sure","userId":"14905985359608653870"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["load AI libraries"],"metadata":{"id":"2KI0AO9VRDXO"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","from tensorflow import keras\n","from keras import layers\n","from keras import models\n","from keras import optimizers"],"metadata":{"id":"XCVs4gzpRElG","executionInfo":{"status":"ok","timestamp":1652988618570,"user_tz":-120,"elapsed":4491,"user":{"displayName":"Simon Sure","userId":"14905985359608653870"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["define folders"],"metadata":{"id":"M818274QR1DM"}},{"cell_type":"code","source":["base_path = os.path.join('/content/drive/MyDrive/FRAI/')\n","\n","samples_path = os.path.join(base_path, 'samples')\n","field_2021_path = os.path.join(samples_path, 'field_2021')\n","simulation_default_path = os.path.join(samples_path, 'simulation_default')\n","\n","tmp_path = os.path.join(samples_path, 'tmp')\n","folds_path = os.path.join(tmp_path, 'folds')\n","validation_path = os.path.join(tmp_path, 'validation')"],"metadata":{"id":"FHAkziE7R3Oz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#defining training parameters"],"metadata":{"id":"xc9yuzyxUf2n"}},{"cell_type":"code","source":["amount_of_folds = 10\n","current_fold = 1\n","\n","amount_of_samples_from_field_2021 = 0\n","amount_of_samples_from_simulation_default = 0\n","#amount_of_samples_from_ = 0\n","\n","batch_size = 10"],"metadata":{"id":"liyUSas8U9ot"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# structuring data for training"],"metadata":{"id":"K7TWF8F5U0ex"}},{"cell_type":"markdown","source":["to be completed"],"metadata":{"id":"LwKbIDlVU8I3"}},{"cell_type":"markdown","source":["# iterators"],"metadata":{"id":"SELNfOVUUoyN"}},{"cell_type":"markdown","source":["training"],"metadata":{"id":"Y_g4YWvzVXaD"}},{"cell_type":"code","source":["def training_generator():\n","  i = 0\n","  training_data = numpy.zeros([batch_size, 120, 160])\n","  training_data_output = numpy.zeros([batch_size, 120, 160])\n","  while True:\n","    for i in range(batch_size):\n","      filename = random.choice(os.listdir(training_data_output_dir))\n","      img_in = cv2.imread(os.path.join(training_data_dir, filename), cv2.IMREAD_GRAYSCALE)\n","      # make image b/w\n","      img_out = cv2.imread(os.path.join(training_data_output_dir, filename), cv2.IMREAD_GRAYSCALE)\n","      training_data[i] = numpy.asarray(img_in)\n","      training_data_output[i] = numpy.asarray(img_out)\n","    training_data = training_data/255.\n","    training_data_output = training_data_output/255.\n","    input = training_data.reshape([batch_size, 120, 160, 1])\n","    label = training_data_output.reshape([batch_size, 120, 160, 1])\n","    inp = tf.convert_to_tensor(training_data)\n","    outp = tf.convert_to_tensor(label)\n","    yield inp, outp"],"metadata":{"id":"hP-gxkHmVVER"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# model"],"metadata":{"id":"GTShNIRuy3kO"}},{"cell_type":"code","source":["pool_size = (2, 2)\n","input_shape = (120, 160, 1)\n","\n","model = models.Sequential()\n","\n","# Normalizes incoming inputs. First layer needs the input shape to work\n","#model.add(layers.normalization.batch_normalization.BatchNormalization(input_shape=input_shape))\n","\n","# Below layers were re-named for easier reading of model summary; this not necessary\n","# Conv Layer 1\n","model.add(layers.Conv2D(8, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv1', input_shape=input_shape))\n","\n","# Conv Layer 2\n","model.add(layers.Conv2D(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv2'))\n","\n","# Pooling 1\n","model.add(layers.MaxPooling2D(pool_size=pool_size))\n","\n","# Conv Layer 3\n","model.add(layers.Conv2D(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv3'))\n","model.add(layers.Dropout(0.2))\n","\n","# Conv Layer 4\n","model.add(layers.Conv2D(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv4'))\n","model.add(layers.Dropout(0.2))\n","\n","# Conv Layer 5\n","model.add(layers.Conv2D(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv5'))\n","model.add(layers.Dropout(0.2))\n","\n","# Pooling 2\n","model.add(layers.MaxPooling2D(pool_size=pool_size))\n","\n","# Conv Layer 6\n","model.add(layers.Conv2D(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv6'))\n","model.add(layers.Dropout(0.2))\n","\n","# Conv Layer 7\n","#model.add(layers.Conv2D(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv7'))\n","#model.add(layers.Dropout(0.2))\n","\n","# Pooling 3\n","model.add(layers.MaxPooling2D(pool_size=pool_size))\n","\n","# Upsample 1\n","model.add(layers.UpSampling2D(size=pool_size))\n","\n","# Deconv 1\n","#model.add(layers.Conv2DTranspose(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv1'))\n","#model.add(layers.Dropout(0.2))\n","\n","# Deconv 2\n","model.add(layers.Conv2DTranspose(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv2'))\n","model.add(layers.Dropout(0.2))\n","\n","# Upsample 2\n","model.add(layers.UpSampling2D(size=pool_size))\n","\n","# Deconv 3\n","model.add(layers.Conv2DTranspose(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv3'))\n","model.add(layers.Dropout(0.2))\n","\n","# Deconv 4\n","model.add(layers.Conv2DTranspose(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv4'))\n","model.add(layers.Dropout(0.2))\n","\n","# Deconv 5\n","model.add(layers.Conv2DTranspose(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv5'))\n","model.add(layers.Dropout(0.2))\n","\n","# Upsample 3\n","model.add(layers.UpSampling2D(size=pool_size))\n","\n","# Deconv 6\n","model.add(layers.Conv2DTranspose(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv6'))\n","\n","# Final layer - only including one channel so 1 filter\n","model.add(layers.Conv2DTranspose(1, (3, 3), padding='valid', strides=(1,1), activation = 'sigmoid', name = 'Final'))\n","\n","model.summary()"],"metadata":{"id":"eBuM7ryRy4jF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(\n","    loss='mean_squared_error',\n","    optimizer='Adam',\n","    metrics=['accuracy']\n",")"],"metadata":{"id":"uJDCaPhEz2pt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# training & testing"],"metadata":{"id":"Li0J14aiU44E"}},{"cell_type":"code","source":["history = model.fit(\n","    training_generator(),\n","    steps_per_epoch=1,\n","    epochs=500\n",")"],"metadata":{"id":"owxIX1XRz-Po"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# validation"],"metadata":{"id":"c90wn1i6U342"}},{"cell_type":"markdown","source":["# export"],"metadata":{"id":"ta5usZGXU28_"}},{"cell_type":"code","source":["model.save('/content/drive/MyDrive/FRAI/model')"],"metadata":{"id":"CV2zwOx10Ifl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# inference"],"metadata":{"id":"Ypl_TTkp0gqE"}},{"cell_type":"code","source":[""],"metadata":{"id":"JP4swO9X0h1N"},"execution_count":null,"outputs":[]}]}